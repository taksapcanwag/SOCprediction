{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f06f3cc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='accounts.google.com', port=443): Max retries exceeded with url: /o/oauth2/token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb518d5d4c0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    175\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/urllib3/util/connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m six\u001b[39m.\u001b[39mraise_from(\n\u001b[1;32m     69\u001b[0m         LocationParseError(\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m host), \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[1;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/socket.py:953\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    952\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 953\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[1;32m    954\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    387\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/urllib3/connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/urllib3/connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    364\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7fb518d5d4c0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    789\u001b[0m )\n\u001b[1;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='accounts.google.com', port=443): Max retries exceeded with url: /o/oauth2/token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb518d5d4c0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mee\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# ee.Authenticate()\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m ee\u001b[39m.\u001b[39;49mInitialize()\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/ee/__init__.py:131\u001b[0m, in \u001b[0;36mInitialize\u001b[0;34m(credentials, opt_url, cloud_api_key, http_transport, project)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m credentials \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpersistent\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    130\u001b[0m   credentials \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mget_persistent_credentials()\n\u001b[0;32m--> 131\u001b[0m data\u001b[39m.\u001b[39;49minitialize(\n\u001b[1;32m    132\u001b[0m     credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[1;32m    133\u001b[0m     api_base_url\u001b[39m=\u001b[39;49m(opt_url \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m/api\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mif\u001b[39;49;00m opt_url \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    134\u001b[0m     tile_base_url\u001b[39m=\u001b[39;49mopt_url,\n\u001b[1;32m    135\u001b[0m     cloud_api_base_url\u001b[39m=\u001b[39;49mopt_url,\n\u001b[1;32m    136\u001b[0m     cloud_api_key\u001b[39m=\u001b[39;49mcloud_api_key,\n\u001b[1;32m    137\u001b[0m     project\u001b[39m=\u001b[39;49mproject,\n\u001b[1;32m    138\u001b[0m     http_transport\u001b[39m=\u001b[39;49mhttp_transport)\n\u001b[1;32m    139\u001b[0m \u001b[39m# Initialize the dynamically loaded functions on the objects that want them.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m ApiFunction\u001b[39m.\u001b[39minitialize()\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/ee/data.py:208\u001b[0m, in \u001b[0;36minitialize\u001b[0;34m(credentials, api_base_url, tile_base_url, cloud_api_base_url, cloud_api_key, project, http_transport)\u001b[0m\n\u001b[1;32m    204\u001b[0m   _cloud_api_client_version \u001b[39m=\u001b[39m version\n\u001b[1;32m    206\u001b[0m _http_transport \u001b[39m=\u001b[39m http_transport\n\u001b[0;32m--> 208\u001b[0m _install_cloud_api_resource()\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m   _cloud_api_user_project \u001b[39m=\u001b[39m project\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/ee/data.py:267\u001b[0m, in \u001b[0;36m_install_cloud_api_resource\u001b[0;34m()\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39mglobal\u001b[39;00m _http_transport\n\u001b[1;32m    266\u001b[0m timeout \u001b[39m=\u001b[39m (_deadline_ms \u001b[39m/\u001b[39m \u001b[39m1000.0\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m _cloud_api_resource \u001b[39m=\u001b[39m _cloud_api_utils\u001b[39m.\u001b[39;49mbuild_cloud_resource(\n\u001b[1;32m    268\u001b[0m     _cloud_api_base_url,\n\u001b[1;32m    269\u001b[0m     credentials\u001b[39m=\u001b[39;49m_credentials,\n\u001b[1;32m    270\u001b[0m     api_key\u001b[39m=\u001b[39;49m_cloud_api_key,\n\u001b[1;32m    271\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    272\u001b[0m     headers_supplier\u001b[39m=\u001b[39;49m_make_request_headers,\n\u001b[1;32m    273\u001b[0m     response_inspector\u001b[39m=\u001b[39;49m_handle_profiling_response,\n\u001b[1;32m    274\u001b[0m     http_transport\u001b[39m=\u001b[39;49m_http_transport)\n\u001b[1;32m    276\u001b[0m _cloud_api_resource_raw \u001b[39m=\u001b[39m _cloud_api_utils\u001b[39m.\u001b[39mbuild_cloud_resource(\n\u001b[1;32m    277\u001b[0m     _cloud_api_base_url,\n\u001b[1;32m    278\u001b[0m     credentials\u001b[39m=\u001b[39m_credentials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m     http_transport\u001b[39m=\u001b[39m_http_transport,\n\u001b[1;32m    284\u001b[0m     raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/ee/_cloud_api_utils.py:178\u001b[0m, in \u001b[0;36mbuild_cloud_resource\u001b[0;34m(api_base_url, api_key, credentials, timeout, headers_supplier, response_inspector, http_transport, raw)\u001b[0m\n\u001b[1;32m    173\u001b[0m resource \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m   \u001b[39m# google-api-python-client made static_discovery the default in version 2,\u001b[39;00m\n\u001b[1;32m    176\u001b[0m   \u001b[39m# but it's not backward-compatible. There's no reliable way to check the\u001b[39;00m\n\u001b[1;32m    177\u001b[0m   \u001b[39m# package version, either.\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m   resource \u001b[39m=\u001b[39m build(static_discovery\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Handle fallback case outside except block, for cleaner stack traces.\u001b[39;00m\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/ee/_cloud_api_utils.py:162\u001b[0m, in \u001b[0;36mbuild_cloud_resource.<locals>.build\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 162\u001b[0m   \u001b[39mreturn\u001b[39;00m discovery\u001b[39m.\u001b[39;49mbuild(\n\u001b[1;32m    163\u001b[0m       \u001b[39m'\u001b[39;49m\u001b[39mearthengine\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    164\u001b[0m       VERSION,\n\u001b[1;32m    165\u001b[0m       discoveryServiceUrl\u001b[39m=\u001b[39;49mdiscovery_service_url,\n\u001b[1;32m    166\u001b[0m       developerKey\u001b[39m=\u001b[39;49mapi_key,\n\u001b[1;32m    167\u001b[0m       http\u001b[39m=\u001b[39;49mhttp_transport,\n\u001b[1;32m    168\u001b[0m       requestBuilder\u001b[39m=\u001b[39;49mrequest_builder,\n\u001b[1;32m    169\u001b[0m       model\u001b[39m=\u001b[39;49malt_model,\n\u001b[1;32m    170\u001b[0m       cache_discovery\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    171\u001b[0m       \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[39melif\u001b[39;00m positional_parameters_enforcement \u001b[39m==\u001b[39m POSITIONAL_WARNING:\n\u001b[1;32m    129\u001b[0m         logger\u001b[39m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/googleapiclient/discovery.py:287\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(serviceName, version, http, discoveryServiceUrl, developerKey, model, requestBuilder, credentials, cache_discovery, cache, client_options, adc_cert_path, adc_key_path, num_retries, static_discovery, always_use_jwt_access)\u001b[0m\n\u001b[1;32m    284\u001b[0m requested_url \u001b[39m=\u001b[39m uritemplate\u001b[39m.\u001b[39mexpand(discovery_url, params)\n\u001b[1;32m    286\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     content \u001b[39m=\u001b[39m _retrieve_discovery_doc(\n\u001b[1;32m    288\u001b[0m         requested_url,\n\u001b[1;32m    289\u001b[0m         discovery_http,\n\u001b[1;32m    290\u001b[0m         cache_discovery,\n\u001b[1;32m    291\u001b[0m         serviceName,\n\u001b[1;32m    292\u001b[0m         version,\n\u001b[1;32m    293\u001b[0m         cache,\n\u001b[1;32m    294\u001b[0m         developerKey,\n\u001b[1;32m    295\u001b[0m         num_retries\u001b[39m=\u001b[39;49mnum_retries,\n\u001b[1;32m    296\u001b[0m         static_discovery\u001b[39m=\u001b[39;49mstatic_discovery,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m     service \u001b[39m=\u001b[39m build_from_document(\n\u001b[1;32m    299\u001b[0m         content,\n\u001b[1;32m    300\u001b[0m         base\u001b[39m=\u001b[39mdiscovery_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m         always_use_jwt_access\u001b[39m=\u001b[39malways_use_jwt_access,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[1;32m    311\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# exit if a service was created\u001b[39;00m\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/googleapiclient/discovery.py:422\u001b[0m, in \u001b[0;36m_retrieve_discovery_doc\u001b[0;34m(url, http, cache_discovery, serviceName, version, cache, developerKey, num_retries, static_discovery)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[39m# Execute this request with retries build into HttpRequest\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39m# Note that it will already raise an error if we don't get a 2xx response\u001b[39;00m\n\u001b[1;32m    421\u001b[0m req \u001b[39m=\u001b[39m HttpRequest(http, HttpRequest\u001b[39m.\u001b[39mnull_postproc, actual_url)\n\u001b[0;32m--> 422\u001b[0m resp, content \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39;49mexecute(num_retries\u001b[39m=\u001b[39;49mnum_retries)\n\u001b[1;32m    424\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    425\u001b[0m     content \u001b[39m=\u001b[39m content\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[39melif\u001b[39;00m positional_parameters_enforcement \u001b[39m==\u001b[39m POSITIONAL_WARNING:\n\u001b[1;32m    129\u001b[0m         logger\u001b[39m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/googleapiclient/http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheaders[\u001b[39m\"\u001b[39m\u001b[39mcontent-length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbody))\n\u001b[1;32m    922\u001b[0m \u001b[39m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[0;32m--> 923\u001b[0m resp, content \u001b[39m=\u001b[39m _retry_request(\n\u001b[1;32m    924\u001b[0m     http,\n\u001b[1;32m    925\u001b[0m     num_retries,\n\u001b[1;32m    926\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrequest\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    927\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sleep,\n\u001b[1;32m    928\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rand,\n\u001b[1;32m    929\u001b[0m     \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muri),\n\u001b[1;32m    930\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmethod),\n\u001b[1;32m    931\u001b[0m     body\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    932\u001b[0m     headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    933\u001b[0m )\n\u001b[1;32m    935\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_callbacks:\n\u001b[1;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/googleapiclient/http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     exception \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     resp, content \u001b[39m=\u001b[39m http\u001b[39m.\u001b[39;49mrequest(uri, method, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    192\u001b[0m \u001b[39m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m _ssl_SSLError \u001b[39mas\u001b[39;00m ssl_error:\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/google_auth_httplib2.py:209\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39m# Make a copy of the headers. They will be modified by the credentials\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m# and we want to pass the original headers if we recurse.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m request_headers \u001b[39m=\u001b[39m headers\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m headers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 209\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcredentials\u001b[39m.\u001b[39;49mbefore_request(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request, method, uri, request_headers)\n\u001b[1;32m    211\u001b[0m \u001b[39m# Check if the body is a file-like stream, and if so, save the body\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m# stream position so that it can be restored in case of refresh.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m body_stream_position \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/google/auth/credentials.py:135\u001b[0m, in \u001b[0;36mCredentials.before_request\u001b[0;34m(self, request, method, url, headers)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m# (Subclasses may use these arguments to ascertain information about\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m# the http request.)\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid:\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrefresh(request)\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(headers)\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/google/oauth2/credentials.py:335\u001b[0m, in \u001b[0;36mCredentials.refresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_refresh_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_token_uri \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client_secret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    322\u001b[0m ):\n\u001b[1;32m    323\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mRefreshError(\n\u001b[1;32m    324\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe credentials do not contain the necessary fields need to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    325\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrefresh the access token. You must specify refresh_token, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtoken_uri, client_id, and client_secret.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n\u001b[1;32m    329\u001b[0m (\n\u001b[1;32m    330\u001b[0m     access_token,\n\u001b[1;32m    331\u001b[0m     refresh_token,\n\u001b[1;32m    332\u001b[0m     expiry,\n\u001b[1;32m    333\u001b[0m     grant_response,\n\u001b[1;32m    334\u001b[0m     rapt_token,\n\u001b[0;32m--> 335\u001b[0m ) \u001b[39m=\u001b[39m reauth\u001b[39m.\u001b[39;49mrefresh_grant(\n\u001b[1;32m    336\u001b[0m     request,\n\u001b[1;32m    337\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_token_uri,\n\u001b[1;32m    338\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_refresh_token,\n\u001b[1;32m    339\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client_id,\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client_secret,\n\u001b[1;32m    341\u001b[0m     scopes\u001b[39m=\u001b[39;49mscopes,\n\u001b[1;32m    342\u001b[0m     rapt_token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rapt_token,\n\u001b[1;32m    343\u001b[0m     enable_reauth_refresh\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_enable_reauth_refresh,\n\u001b[1;32m    344\u001b[0m )\n\u001b[1;32m    346\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken \u001b[39m=\u001b[39m access_token\n\u001b[1;32m    347\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpiry \u001b[39m=\u001b[39m expiry\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/google/oauth2/reauth.py:324\u001b[0m, in \u001b[0;36mrefresh_grant\u001b[0;34m(request, token_uri, refresh_token, client_id, client_secret, scopes, rapt_token, enable_reauth_refresh)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mif\u001b[39;00m rapt_token:\n\u001b[1;32m    322\u001b[0m     body[\u001b[39m\"\u001b[39m\u001b[39mrapt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m rapt_token\n\u001b[0;32m--> 324\u001b[0m response_status_ok, response_data, retryable_error \u001b[39m=\u001b[39m _client\u001b[39m.\u001b[39;49m_token_endpoint_request_no_throw(\n\u001b[1;32m    325\u001b[0m     request, token_uri, body\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    328\u001b[0m     \u001b[39mnot\u001b[39;00m response_status_ok\n\u001b[1;32m    329\u001b[0m     \u001b[39mand\u001b[39;00m response_data\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m _REAUTH_NEEDED_ERROR\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m ):\n\u001b[1;32m    335\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m enable_reauth_refresh:\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/google/oauth2/_client.py:213\u001b[0m, in \u001b[0;36m_token_endpoint_request_no_throw\u001b[0;34m(request, token_uri, body, access_token, use_json, can_retry, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     retryable_error \u001b[39m=\u001b[39m _can_retry(\n\u001b[1;32m    208\u001b[0m         status_code\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mstatus, response_data\u001b[39m=\u001b[39mresponse_data\n\u001b[1;32m    209\u001b[0m     )\n\u001b[1;32m    211\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m, response_data, retryable_error\n\u001b[0;32m--> 213\u001b[0m request_succeeded, response_data, retryable_error \u001b[39m=\u001b[39m _perform_request()\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m request_succeeded \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m retryable_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m can_retry:\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m request_succeeded, response_data, retryable_error\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/google/oauth2/_client.py:189\u001b[0m, in \u001b[0;36m_token_endpoint_request_no_throw.<locals>._perform_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_perform_request\u001b[39m():\n\u001b[0;32m--> 189\u001b[0m     response \u001b[39m=\u001b[39m request(\n\u001b[1;32m    190\u001b[0m         method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, url\u001b[39m=\u001b[39;49mtoken_uri, headers\u001b[39m=\u001b[39;49mheaders, body\u001b[39m=\u001b[39;49mbody, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    192\u001b[0m     response_body \u001b[39m=\u001b[39m (\n\u001b[1;32m    193\u001b[0m         response\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    194\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(response\u001b[39m.\u001b[39mdata, \u001b[39m\"\u001b[39m\u001b[39mdecode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    195\u001b[0m         \u001b[39melse\u001b[39;00m response\u001b[39m.\u001b[39mdata\n\u001b[1;32m    196\u001b[0m     )\n\u001b[1;32m    197\u001b[0m     response_data \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/google_auth_httplib2.py:119\u001b[0m, in \u001b[0;36mRequest.__call__\u001b[0;34m(self, url, method, body, headers, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     _LOGGER\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mMaking request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, method, url)\n\u001b[0;32m--> 119\u001b[0m     response, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhttp\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    120\u001b[0m         url, method\u001b[39m=\u001b[39;49mmethod, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m _Response(response, data)\n\u001b[1;32m    123\u001b[0m \u001b[39m# httplib2 should catch the lower http error, this is a bug and\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# needs to be fixed there.  Catch the error for the meanwhile.\u001b[39;00m\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/ee/_cloud_api_utils.py:62\u001b[0m, in \u001b[0;36m_Http.request\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m requests\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m     61\u001b[0m   session\u001b[39m.\u001b[39mmax_redirects \u001b[39m=\u001b[39m redirections\n\u001b[0;32m---> 62\u001b[0m   response \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m     63\u001b[0m       method, uri, data\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders, timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout)\n\u001b[1;32m     64\u001b[0m   headers \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(response\u001b[39m.\u001b[39mheaders)\n\u001b[1;32m     65\u001b[0m   headers[\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus_code\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/carbon/lib/python3.9/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    522\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='accounts.google.com', port=443): Max retries exceeded with url: /o/oauth2/token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb518d5d4c0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))"
     ]
    }
   ],
   "source": [
    "# Import, authenticate and initialize the Earth Engine library\n",
    "import ee\n",
    "# ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb9384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/home/shoyo/carbon/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/home/shoyo/carbon/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/home/shoyo/carbon/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/home/shoyo/carbon/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/home/shoyo/carbon/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from dateutil.relativedelta import *\n",
    "!pip install geopandas --quiet\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "# !pip install datatable --quiet\n",
    "!pip install git+https://github.com/h2oai/datatable --quiet\n",
    "# !pip install datatable --quiet\n",
    "import datatable as dt\n",
    "from datatable import f\n",
    "import time\n",
    "from pprint import pprint\n",
    "import os, re\n",
    "!pip install gee_subset --quiet\n",
    "from gee_subset import gee_subset\n",
    "import shapely.geometry\n",
    "import re\n",
    "!pip install geemap --quiet\n",
    "import geemap\n",
    "!pip install git+https://github.com/loicdtx/landsat-extract-gee --quiet\n",
    "# !pip install geextract\n",
    "import geextract\n",
    "from geextract import ts_extract\n",
    "import math\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "486b8bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>year</th>\n",
       "      <th>SOC</th>\n",
       "      <th>LC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.191816</td>\n",
       "      <td>1.378330</td>\n",
       "      <td>2021</td>\n",
       "      <td>6.84225</td>\n",
       "      <td>cropland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.193972</td>\n",
       "      <td>1.385067</td>\n",
       "      <td>2021</td>\n",
       "      <td>5.94385</td>\n",
       "      <td>cropland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.195589</td>\n",
       "      <td>1.384528</td>\n",
       "      <td>2021</td>\n",
       "      <td>4.45060</td>\n",
       "      <td>wooded_grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.190468</td>\n",
       "      <td>1.378869</td>\n",
       "      <td>2021</td>\n",
       "      <td>7.10625</td>\n",
       "      <td>wooded_grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.187234</td>\n",
       "      <td>1.379678</td>\n",
       "      <td>2021</td>\n",
       "      <td>7.06505</td>\n",
       "      <td>wooded_grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>34.343447</td>\n",
       "      <td>0.154286</td>\n",
       "      <td>2021</td>\n",
       "      <td>11.69960</td>\n",
       "      <td>cropland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>34.342908</td>\n",
       "      <td>0.158328</td>\n",
       "      <td>2021</td>\n",
       "      <td>17.27550</td>\n",
       "      <td>cropland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>34.342099</td>\n",
       "      <td>0.159676</td>\n",
       "      <td>2021</td>\n",
       "      <td>16.55060</td>\n",
       "      <td>bushland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>34.343177</td>\n",
       "      <td>0.160754</td>\n",
       "      <td>2021</td>\n",
       "      <td>11.26630</td>\n",
       "      <td>cropland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>34.346142</td>\n",
       "      <td>0.157520</td>\n",
       "      <td>2021</td>\n",
       "      <td>13.22570</td>\n",
       "      <td>cropland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2254 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      longitude  latitude  year       SOC                LC\n",
       "0     35.191816  1.378330  2021   6.84225          cropland\n",
       "1     35.193972  1.385067  2021   5.94385          cropland\n",
       "2     35.195589  1.384528  2021   4.45060  wooded_grassland\n",
       "3     35.190468  1.378869  2021   7.10625  wooded_grassland\n",
       "4     35.187234  1.379678  2021   7.06505  wooded_grassland\n",
       "...         ...       ...   ...       ...               ...\n",
       "2249  34.343447  0.154286  2021  11.69960          cropland\n",
       "2250  34.342908  0.158328  2021  17.27550          cropland\n",
       "2251  34.342099  0.159676  2021  16.55060          bushland\n",
       "2252  34.343177  0.160754  2021  11.26630          cropland\n",
       "2253  34.346142  0.157520  2021  13.22570          cropland\n",
       "\n",
       "[2254 rows x 5 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir('/home/shoyo/Desktop')\n",
    "\n",
    "csv_path = '/SOC_LonLatYearLC.csv'\n",
    "df = pd.read_csv(os.getcwd() + csv_path)\n",
    "# df = df.drop(columns=['other', 'Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a7cc3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloudMask(image):\n",
    "  \n",
    "  qa = image.select('QA_PIXEL')\n",
    "  dilated = 1 << 1\n",
    "  cirrus = 1 << 2\n",
    "  cloud = 1 << 3\n",
    "  shadow = 1 << 4\n",
    "\n",
    "  # mask = ((qa.bitwise_and(dilated) == 0) & (qa.bitwise_and(cirrus) == 0) & (qa.bitwise_and(cloud) == 0) & (qa.bitwise_and(shadow) == 0))\n",
    "  # mask = ((qa.bitwise_and(1 << 1) == 0) & (qa.bitwise_and(1 << 2) == 0) & (qa.bitwise_and(1 << 3) == 0) & (qa.bitwise_and(1 << 4) == 0))\n",
    "  mask = ((qa.bitwise_and(1 << 3).neq(0)).multiply(1)\n",
    "      .add((qa.bitwise_and(1 << 4).neq(0)).multiply(1))\n",
    "      .add((qa.bitwise_and(1 << 2).neq(0)).multiply(1))\n",
    "      # .add((qa.bitwise_and(1 << 1).neq(0)).multiply(1))\n",
    "      )\n",
    "\n",
    "  return image.updateMask(mask)\n",
    "\n",
    "def addEVI(image):\n",
    "\n",
    "  SR = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "  image = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
    "  image = image.addBands(SR, None, True)\n",
    "\n",
    "  evi = image.expression( '2.5 * ( (NIR-RED) / (NIR + 6*RED - 7.5*BLUE + 1))', {\n",
    "      'NIR': image.select('SR_B5'),\n",
    "      'RED': image.select('SR_B4'),\n",
    "      'BLUE': image.select('SR_B2'),\n",
    "      }).rename('EVI')\n",
    "  return image.addBands(evi)\n",
    "\n",
    "def get_landsat(lon, lat, start, end):\n",
    "  point = ee.Geometry.Point(lon, lat).buffer(15).bounds()\n",
    "  landsat8 = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\").filterDate(start, end).filterBounds(point).map(cloudMask).map(addEVI).select(['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'EVI', 'ST_B10'])\n",
    "  landsat9 = ee.ImageCollection(\"LANDSAT/LC09/C02/T1_L2\").filterDate(start, end).filterBounds(point).map(cloudMask).map(addEVI).select(['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'EVI', 'ST_B10'])\n",
    "  # landsat = landsat8.merge(landsat9).reduce(ee.Reducer.median(), bestEffort=True)\n",
    "  landsat = landsat8.merge(landsat9).median()\n",
    "  # landsat = landsat.updateMask(landsat.mask())\n",
    "  landsat = ee.ImageCollection.fromImages([landsat]).getRegion(point, 30).getInfo()\n",
    "\n",
    "  return landsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d83168fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear to db scale\n",
    "def lin_to_db(image):\n",
    "    bandNames = image.bandNames().remove('angle')\n",
    "    db = ee.Image.constant(10).multiply(image.select(bandNames).log10()).rename(bandNames)\n",
    "    return image.addBands(db, None, True)\n",
    "\n",
    "def db_to_lin(image):\n",
    "    bandNames = image.bandNames().remove('angle')\n",
    "    lin = ee.Image.constant(10).pow(image.select(bandNames).divide(10)).rename(bandNames)\n",
    "    return image.addBands(lin, None, True)\n",
    "\n",
    "def lin_to_db2(image):\n",
    "    db = ee.Image.constant(10).multiply(image.select(['VV', 'VH']).log10()).rename(['VV', 'VH'])\n",
    "    return image.addBands(db, None, True)\n",
    "\n",
    "# Add ratio bands\n",
    "def add_ratio_lin(image):\n",
    "    ratio = image.addBands(image.select('VV').divide(image.select('VH')).rename('VVVH_ratio'))\n",
    "    \n",
    "    return ratio.set('system:time_start', image.get('system:time_start'))\n",
    "\n",
    "# Additional Border Noise Removal\n",
    "def maskAngLT452(image):\n",
    "    ang = image.select(['angle'])\n",
    "    return image.updateMask(ang.lt(45.23993)).set('system:time_start', image.get('system:time_start'))\n",
    "\n",
    "def maskAngGT30(image):\n",
    "    ang = image.select(['angle'])\n",
    "    return image.updateMask(ang.gt(30.63993)).set('system:time_start', image.get('system:time_start'))\n",
    "\n",
    "def maskEdge(image):\n",
    "    mask = image.select(0).unitScale(-25, 5).multiply(255).toByte()#.connectedComponents(ee.Kernel.rectangle(1,1), 100)\n",
    "    return image.updateMask(mask.select(0)).set('system:time_start', image.get('system:time_start')) \n",
    "\n",
    "def f_mask_edges(image):\n",
    "    db_img = lin_to_db(image)\n",
    "    output = maskAngGT30(db_img)\n",
    "    output = maskAngLT452(output)\n",
    "    #output = maskEdge(output)\n",
    "    output = db_to_lin(output)\n",
    "    return output.set('system:time_start', image.get('system:time_start'))\n",
    "\n",
    "# 1.SPECKLE FILTERS\n",
    "def boxcar(image, KERNEL_SIZE):\n",
    "    bandNames = image.bandNames().remove('angle')\n",
    "      #Define a boxcar kernel\n",
    "    kernel = ee.Kernel.square((KERNEL_SIZE/2), units='pixels', normalize=True)\n",
    "     #Apply boxcar\n",
    "    output = image.select(bandNames).convolve(kernel).rename(bandNames)\n",
    "    return image.addBands(output, None, True)\n",
    "\n",
    "def RefinedLee(image):\n",
    "    \"\"\"\n",
    "    This filter is modified from the implementation by Guido Lemoine \n",
    "    Source: Lemoine et al. https://code.earthengine.google.com/5d1ed0a0f0417f098fdfd2fa137c3d0c\n",
    "    \"\"\"\n",
    "    bandNames = image.bandNames().remove('angle')\n",
    "    def inner(b):\n",
    "\n",
    "        img = image.select([b]);\n",
    "    \n",
    "        # img must be linear, i.e. not in dB!\n",
    "        # Set up 3x3 kernels \n",
    "        weights3 = ee.List.repeat(ee.List.repeat(1,3),3);\n",
    "        kernel3 = ee.Kernel.fixed(3,3, weights3, 1, 1, False);\n",
    "  \n",
    "        mean3 = img.reduceNeighborhood(ee.Reducer.mean(), kernel3);\n",
    "        variance3 = img.reduceNeighborhood(ee.Reducer.variance(), kernel3);\n",
    "  \n",
    "        # Use a sample of the 3x3 windows inside a 7x7 windows to determine gradients and directions\n",
    "        sample_weights = ee.List([[0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0], [0,1,0,1,0,1,0], [0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0]]);\n",
    "  \n",
    "        sample_kernel = ee.Kernel.fixed(7,7, sample_weights, 3,3, False);\n",
    "  \n",
    "        # Calculate mean and variance for the sampled windows and store as 9 bands\n",
    "        sample_mean = mean3.neighborhoodToBands(sample_kernel); \n",
    "        sample_var = variance3.neighborhoodToBands(sample_kernel);\n",
    "  \n",
    "        # Determine the 4 gradients for the sampled windows\n",
    "        gradients = sample_mean.select(1).subtract(sample_mean.select(7)).abs();\n",
    "        gradients = gradients.addBands(sample_mean.select(6).subtract(sample_mean.select(2)).abs());\n",
    "        gradients = gradients.addBands(sample_mean.select(3).subtract(sample_mean.select(5)).abs());\n",
    "        gradients = gradients.addBands(sample_mean.select(0).subtract(sample_mean.select(8)).abs());\n",
    "  \n",
    "        # And find the maximum gradient amongst gradient bands\n",
    "        max_gradient = gradients.reduce(ee.Reducer.max());\n",
    "  \n",
    "        # Create a mask for band pixels that are the maximum gradient\n",
    "        gradmask = gradients.eq(max_gradient);\n",
    "  \n",
    "        # duplicate gradmask bands: each gradient represents 2 directions\n",
    "        gradmask = gradmask.addBands(gradmask);\n",
    "  \n",
    "        # Determine the 8 directions\n",
    "        directions = sample_mean.select(1).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(7))).multiply(1);\n",
    "        directions = directions.addBands(sample_mean.select(6).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(2))).multiply(2));\n",
    "        directions = directions.addBands(sample_mean.select(3).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(5))).multiply(3));\n",
    "        directions = directions.addBands(sample_mean.select(0).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(8))).multiply(4));\n",
    "        # The next 4 are the not() of the previous 4\n",
    "        directions = directions.addBands(directions.select(0).Not().multiply(5));\n",
    "        directions = directions.addBands(directions.select(1).Not().multiply(6));\n",
    "        directions = directions.addBands(directions.select(2).Not().multiply(7));\n",
    "        directions = directions.addBands(directions.select(3).Not().multiply(8));\n",
    "  \n",
    "        # Mask all values that are not 1-8\n",
    "        directions = directions.updateMask(gradmask);\n",
    "  \n",
    "        # \"collapse\" the stack into a singe band image (due to masking, each pixel has just one value (1-8) in it's directional band, and is otherwise masked)\n",
    "        directions = directions.reduce(ee.Reducer.sum());  \n",
    "  \n",
    "        sample_stats = sample_var.divide(sample_mean.multiply(sample_mean));\n",
    "  \n",
    "        #Calculate localNoiseVariance\n",
    "        sigmaV = sample_stats.toArray().arraySort().arraySlice(0,0,5).arrayReduce(ee.Reducer.mean(), [0]);\n",
    "  \n",
    "        # Set up the 7*7 kernels for directional statistics\n",
    "        rect_weights = ee.List.repeat(ee.List.repeat(0,7),3).cat(ee.List.repeat(ee.List.repeat(1,7),4));\n",
    "  \n",
    "        diag_weights = ee.List([[1,0,0,0,0,0,0], [1,1,0,0,0,0,0], [1,1,1,0,0,0,0], [1,1,1,1,0,0,0], [1,1,1,1,1,0,0], [1,1,1,1,1,1,0], [1,1,1,1,1,1,1]]);\n",
    "  \n",
    "        rect_kernel = ee.Kernel.fixed(7,7, rect_weights, 3, 3, False);\n",
    "        diag_kernel = ee.Kernel.fixed(7,7, diag_weights, 3, 3, False);\n",
    "  \n",
    "        # Create stacks for mean and variance using the original kernels. Mask with relevant direction.\n",
    "        dir_mean = img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel).updateMask(directions.eq(1));\n",
    "        dir_var = img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel).updateMask(directions.eq(1));\n",
    "  \n",
    "        dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel).updateMask(directions.eq(2)));\n",
    "        dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel).updateMask(directions.eq(2)));\n",
    "  \n",
    "        # and add the bands for rotated kernels\n",
    "        for i in range(1, 4):\n",
    "            dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n",
    "            dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n",
    "            dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n",
    "            dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n",
    "\n",
    "  \n",
    "        # \"collapse\" the stack into a single band image (due to masking, each pixel has just one value in it's directional band, and is otherwise masked)\n",
    "        dir_mean = dir_mean.reduce(ee.Reducer.sum());\n",
    "        dir_var = dir_var.reduce(ee.Reducer.sum());\n",
    "  \n",
    "        # A finally generate the filtered value\n",
    "        varX = dir_var.subtract(dir_mean.multiply(dir_mean).multiply(sigmaV)).divide(sigmaV.add(1.0))\n",
    "  \n",
    "        b = varX.divide(dir_var)\n",
    "        result = dir_mean.add(b.multiply(img.subtract(dir_mean)))\n",
    "  \n",
    "        return result.arrayProject([0]).arrayFlatten([['sum']]).float()\n",
    "    \n",
    "    result = ee.ImageCollection(bandNames.map(inner)).toBands().rename(bandNames).copyProperties(image)\n",
    "    \n",
    "    return image.addBands(result, None, True) \n",
    "\n",
    "\n",
    "# 2. MONO-TEMPORAL SPECKLE FILTER (WRAPPER)\n",
    "def MonoTemporal_Filter(coll,KERNEL_SIZE, SPECKLE_FILTER) :\n",
    "    def _filter(image):    \n",
    "      #  if (SPECKLE_FILTER=='BOXCAR'):\n",
    "      #     _filtered = boxcar(image, KERNEL_SIZE)\n",
    "      #  elif (SPECKLE_FILTER=='LEE'):\n",
    "      #     _filtered = leefilter(image, KERNEL_SIZE)\n",
    "      #  elif (SPECKLE_FILTER=='GAMMA MAP'):\n",
    "      #     _filtered = gammamap(image, KERNEL_SIZE)\n",
    "       if (SPECKLE_FILTER=='REFINED LEE'):\n",
    "          _filtered = RefinedLee(image)\n",
    "      #  elif (SPECKLE_FILTER=='LEE SIGMA'):\n",
    "      #     _filtered = leesigma(image, KERNEL_SIZE)\n",
    "      #  return _filtered\n",
    "    return coll.map(_filter)\n",
    "\n",
    "\n",
    "# 3. MULTI-TEMPORAL SPECKLE FILTER\n",
    "def MultiTemporal_Filter(coll,KERNEL_SIZE, SPECKLE_FILTER,NR_OF_IMAGES):\n",
    "    def Quegan(image) :\n",
    "        \"\"\"\n",
    "        The following Multi-temporal speckle filters are implemented as described in\n",
    "        S. Quegan and J. J. Yu, “Filtering of multichannel SAR images,” \n",
    "        IEEE Trans Geosci. Remote Sensing, vol. 39, Nov. 2001.\n",
    "        \"\"\"\n",
    "        def setresample(image):\n",
    "                return image.resample()\n",
    "            \n",
    "        def get_filtered_collection(image):  \n",
    "            #filter collection over are and by relative orbit\n",
    "            s1_coll = ee.ImageCollection('COPERNICUS/S1_GRD_FLOAT') \\\n",
    "                .filterBounds(image.geometry()) \\\n",
    "                .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "                .filter(ee.Filter.listContains('transmitterReceiverPolarisation', ee.List(image.get('transmitterReceiverPolarisation')).get(-1))) \\\n",
    "                .filter(ee.Filter.Or(ee.Filter.eq('relativeOrbitNumber_stop', image.get('relativeOrbitNumber_stop')), \\\n",
    "                                     ee.Filter.eq('relativeOrbitNumber_stop', image.get('relativeOrbitNumber_start'))\n",
    "                )).map(setresample)\n",
    "      \n",
    "            #a function that takes the image and checks for the overlap\n",
    "            def check_overlap(_image):\n",
    "                # get all S1 frames from this date intersecting with the image bounds\n",
    "                s1 = s1_coll.filterDate(_image.date(), _image.date().advance(1, 'day'))\n",
    "                # intersect those images with the image to filter\n",
    "                intersect = image.geometry().intersection(s1.geometry().dissolve(), 10)\n",
    "                # check if intersect is sufficient\n",
    "                valid_date = ee.Algorithms.If(intersect.area(10).divide(image.geometry().area(10)).gt(0.95), \\\n",
    "                                              _image.date().format('YYYY-MM-dd')\n",
    "                                              )\n",
    "                return ee.Feature(None, {'date': valid_date})\n",
    "      \n",
    "      \n",
    "            # this function will pick up the acq dates for fully overlapping acquisitions before the image acquistion\n",
    "            dates_before = s1_coll.filterDate('2014-01-01', image.date().advance(1, 'day')) \\\n",
    "                                    .sort('system:time_start', False).limit(5*NR_OF_IMAGES) \\\n",
    "                                    .map(check_overlap).distinct('date').aggregate_array('date')\n",
    "    \n",
    "            # if the images before are not enough, we add images from after the image acquisition \n",
    "            # this will only be the case at the beginning of S1 mission\n",
    "            dates = ee.List(ee.Algorithms.If( \\\n",
    "                                             dates_before.size().gte(NR_OF_IMAGES), \\\n",
    "                                                 dates_before.slice(0, NR_OF_IMAGES), \\\n",
    "                                                     s1_coll \\\n",
    "                                                         .filterDate(image.date(), '2100-01-01') \\\n",
    "                                                             .sort('system:time_start', True).limit(5*NR_OF_IMAGES) \\\n",
    "                                                                 .map(check_overlap) \\\n",
    "                                                                     .distinct('date') \\\n",
    "                                                                         .aggregate_array('date') \\\n",
    "                                                                             .cat(dates_before).distinct().sort().slice(0, NR_OF_IMAGES)\n",
    "                                                                             )\n",
    "                                                )\n",
    "    \n",
    "            #now we re-filter the collection to get the right acquisitions for multi-temporal filtering\n",
    "            return ee.ImageCollection(dates.map(lambda date: s1_coll.filterDate(date, ee.Date(date).advance(1,'day')).toList(s1_coll.size())).flatten())\n",
    "      \n",
    "          \n",
    "  \n",
    "        #we get our dedicated image collection for that image\n",
    "        s1 = get_filtered_collection(image)\n",
    "  \n",
    "        bands = image.bandNames().remove('angle')\n",
    "        s1 = s1.select(bands)\n",
    "        meanBands = bands.map(lambda bandName: ee.String(bandName).cat('_mean'))\n",
    "        ratioBands = bands.map(lambda bandName: ee.String(bandName).cat('_ratio'))\n",
    "        count_img = s1.reduce(ee.Reducer.count())\n",
    "\n",
    "        def inner(image):\n",
    "            # if (SPECKLE_FILTER=='BOXCAR'):\n",
    "            #     _filtered = boxcar(image, KERNEL_SIZE).select(bands).rename(meanBands) \n",
    "            # elif (SPECKLE_FILTER=='LEE'):\n",
    "            #     _filtered = leefilter(image, KERNEL_SIZE).select(bands).rename(meanBands)\n",
    "            # elif (SPECKLE_FILTER=='GAMMA MAP'):\n",
    "            #     _filtered = gammamap(image, KERNEL_SIZE).select(bands).rename(meanBands)\n",
    "            if (SPECKLE_FILTER=='REFINED LEE'):\n",
    "                _filtered = RefinedLee(image).select(bands).rename(meanBands)\n",
    "            # elif (SPECKLE_FILTER=='LEE SIGMA'):\n",
    "            #     _filtered = leesigma(image, KERNEL_SIZE).select(bands).rename(meanBands)\n",
    "    \n",
    "            _ratio = image.select(bands).divide(_filtered).rename(ratioBands) \n",
    "            return _filtered.addBands(_ratio)\n",
    "\n",
    "        isum = s1.map(inner).select(ratioBands).reduce(ee.Reducer.sum())\n",
    "        filtered = inner(image).select(meanBands)\n",
    "        divide = filtered.divide(count_img)\n",
    "        output = divide.multiply(isum).rename(bands)\n",
    "\n",
    "        return image.addBands(output, None, True)\n",
    "    return coll.map(Quegan)\n",
    "\n",
    "# Terrain Flattening\n",
    "def slope_correction(collection, TERRAIN_FLATTENING_MODEL, DEM, TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER):\n",
    "    ninetyRad = ee.Image.constant(90).multiply(math.pi/180)\n",
    "\n",
    "    def _volumetric_model_SCF(theta_iRad, alpha_rRad):\n",
    "        # Volume model\n",
    "        nominator = (ninetyRad.subtract(theta_iRad).add(alpha_rRad)).tan()\n",
    "        denominator = (ninetyRad.subtract(theta_iRad)).tan()\n",
    "        return nominator.divide(denominator)\n",
    "\n",
    "    def _direct_model_SCF(theta_iRad, alpha_rRad, alpha_azRad):\n",
    "        # Surface model\n",
    "        nominator = (ninetyRad.subtract(theta_iRad)).cos()\n",
    "        denominator = alpha_azRad.cos().multiply((ninetyRad.subtract(theta_iRad).add(alpha_rRad)).cos())\n",
    "        return nominator.divide(denominator)\n",
    "\n",
    "    def _erode(image, distance):\n",
    "        # buffer function (thanks Noel)\n",
    "        d = (image.Not().unmask(1).fastDistanceTransform(30).sqrt()\n",
    "             .multiply(ee.Image.pixelArea().sqrt()))\n",
    "        return image.updateMask(d.gt(distance))\n",
    "\n",
    "    def _masking(alpha_rRad, theta_iRad, buffer):\n",
    "        # calculate masks\n",
    "        # layover, where slope > radar viewing angle\n",
    "        layover = alpha_rRad.lt(theta_iRad).rename('layover')\n",
    "        # shadow\n",
    "        shadow = alpha_rRad.gt(ee.Image.constant(-1)\n",
    "                        .multiply(ninetyRad.subtract(theta_iRad))).rename('shadow')\n",
    "        # combine layover and shadow\n",
    "        mask = layover.And(shadow)\n",
    "        # add buffer to final mask\n",
    "        if (buffer > 0):\n",
    "            mask = _erode(mask, buffer)\n",
    "        return mask.rename('no_data_mask')\n",
    "\n",
    "    def _correct(image):\n",
    "        bandNames = image.bandNames()\n",
    "        geom = image.geometry()\n",
    "        proj = image.select(1).projection()\n",
    "        elevation = DEM.resample('bilinear').reproject(proj,None, 10).clip(geom)\n",
    "        # calculate the look direction\n",
    "        heading = ee.Terrain.aspect(image.select('angle')).reduceRegion(ee.Reducer.mean(), image.geometry(), 1000)\n",
    "        \n",
    "        #in case of null values for heading replace with 0\n",
    "        heading = ee.Dictionary(heading).combine({'aspect': 0}, False).get('aspect')\n",
    "        \n",
    "        heading = ee.Algorithms.If(\n",
    "            ee.Number(heading).gt(180),\n",
    "            ee.Number(heading).subtract(360),\n",
    "            ee.Number(heading)\n",
    "        )\n",
    "        \n",
    "        # the numbering follows the article chapters\n",
    "        # 2.1.1 Radar geometry\n",
    "        theta_iRad = image.select('angle').multiply(math.pi/180)\n",
    "        phi_iRad = ee.Image.constant(heading).multiply(math.pi/180)\n",
    "        \n",
    "        # 2.1.2 Terrain geometry\n",
    "        alpha_sRad = ee.Terrain.slope(elevation).select('slope').multiply(math.pi / 180)\n",
    "\n",
    "        aspect = ee.Terrain.aspect(elevation).select('aspect').clip(geom)\n",
    "        \n",
    "        aspect_minus = aspect.updateMask(aspect.gt(180)).subtract(360)\n",
    "        \n",
    "        phi_sRad = aspect.updateMask(aspect.lte(180))\\\n",
    "            .unmask()\\\n",
    "            .add(aspect_minus.unmask())\\\n",
    "            .multiply(-1)\\\n",
    "            .multiply(math.pi / 180)\n",
    "          \n",
    "        #elevation = DEM.reproject(proj,None, 10).clip(geom)\n",
    "\n",
    "        # 2.1.3 Model geometry\n",
    "        # reduce to 3 angle\n",
    "        phi_rRad = phi_iRad.subtract(phi_sRad)\n",
    "\n",
    "        # slope steepness in range (eq. 2)\n",
    "        alpha_rRad = (alpha_sRad.tan().multiply(phi_rRad.cos())).atan()\n",
    "\n",
    "        # slope steepness in azimuth (eq 3)\n",
    "        alpha_azRad = (alpha_sRad.tan().multiply(phi_rRad.sin())).atan()\n",
    "\n",
    "        # 2.2\n",
    "        # Gamma_nought\n",
    "        gamma0 = image.divide(theta_iRad.cos())\n",
    "\n",
    "        if (TERRAIN_FLATTENING_MODEL == 'VOLUME'):\n",
    "            # Volumetric Model\n",
    "            scf = _volumetric_model_SCF(theta_iRad, alpha_rRad)\n",
    "\n",
    "        if (TERRAIN_FLATTENING_MODEL == 'DIRECT'):\n",
    "            scf = _direct_model_SCF(theta_iRad, alpha_rRad, alpha_azRad)\n",
    "\n",
    "        # apply model for Gamm0\n",
    "        gamma0_flat = gamma0.multiply(scf)\n",
    "\n",
    "        # get Layover/Shadow mask\n",
    "        mask = _masking(alpha_rRad, theta_iRad, TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER)\n",
    "        output = gamma0_flat.mask(mask).rename(bandNames).copyProperties(image)\n",
    "        output = ee.Image(output).addBands(image.select('angle'), None, True)\n",
    "\n",
    "        return output.set('system:time_start', image.get('system:time_start'))\n",
    "    return collection.map(_correct)\n",
    "\n",
    "def s1_preproc(params):\n",
    "    APPLY_BORDER_NOISE_CORRECTION = params['APPLY_BORDER_NOISE_CORRECTION']\n",
    "    APPLY_TERRAIN_FLATTENING = params['APPLY_TERRAIN_FLATTENING']\n",
    "    APPLY_SPECKLE_FILTERING = params['APPLY_SPECKLE_FILTERING']\n",
    "    POLARIZATION = params['POLARIZATION']\n",
    "    # PLATFORM_NUMBER = params['PLATFORM_NUMBER']\n",
    "    ORBIT = params['ORBIT']\n",
    "    # ORBIT_NUM = params['ORBIT_NUM']\n",
    "    SPECKLE_FILTER_FRAMEWORK = params['SPECKLE_FILTER_FRAMEWORK']\n",
    "    SPECKLE_FILTER = params['SPECKLE_FILTER']\n",
    "    SPECKLE_FILTER_KERNEL_SIZE = params['SPECKLE_FILTER_KERNEL_SIZE']\n",
    "    SPECKLE_FILTER_NR_OF_IMAGES = params['SPECKLE_FILTER_NR_OF_IMAGES']\n",
    "    TERRAIN_FLATTENING_MODEL = params['TERRAIN_FLATTENING_MODEL']\n",
    "    DEM = params['DEM']\n",
    "    TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER = params['TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER']\n",
    "    FORMAT = params['FORMAT']\n",
    "    START_DATE = params['START_DATE']\n",
    "    STOP_DATE = params['STOP_DATE']\n",
    "    ROI = params['ROI']\n",
    "    CLIP_TO_ROI = params['CLIP_TO_ROI']\n",
    "    SAVE_ASSET = params['SAVE_ASSET']\n",
    "    # ASSET_ID = params['ASSET_ID']\n",
    "\n",
    "    # 0. CHECK PARAMETERS\n",
    "    if APPLY_BORDER_NOISE_CORRECTION is None:\n",
    "        APPLY_BORDER_NOISE_CORRECTION = True\n",
    "    if APPLY_TERRAIN_FLATTENING is None:\n",
    "        APPLY_TERRAIN_FLATTENING = True\n",
    "    if APPLY_SPECKLE_FILTERING is None:\n",
    "        APPLY_SPECKLE_FILTERING = True\n",
    "    if POLARIZATION is None:\n",
    "        POLARIZATION = 'VVVH'\n",
    "    if ORBIT is None:\n",
    "        ORBIT = 'BOTH'\n",
    "    if SPECKLE_FILTER_FRAMEWORK is None:\n",
    "        SPECKLE_FILTER_FRAMEWORK = 'MULTI BOXCAR'\n",
    "    if SPECKLE_FILTER is None:\n",
    "        SPECKLE_FILTER = 'GAMMA MAP'\n",
    "    if SPECKLE_FILTER_KERNEL_SIZE is None:\n",
    "        SPECKLE_FILTER_KERNEL_SIZE = 7\n",
    "    if SPECKLE_FILTER_NR_OF_IMAGES is None:\n",
    "        SPECKLE_FILTER_NR_OF_IMAGES = 10\n",
    "    if TERRAIN_FLATTENING_MODEL is None:\n",
    "        TERRAIN_FLATTENING_MODEL = 'VOLUME'\n",
    "    if TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER is None:\n",
    "        TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER = 0\n",
    "    if FORMAT is None:\n",
    "        FORMAT = 'DB'\n",
    "    # if ORBIT is None:\n",
    "    #     ORBIT = 'DESCENDING'\n",
    "\n",
    "    pol_required = ['VV', 'VH', 'VVVH']\n",
    "    if (POLARIZATION not in pol_required):\n",
    "        raise ValueError(\"ERROR!!! Parameter POLARIZATION not correctly defined\")\n",
    "\n",
    "    orbit_required = ['ASCENDING', 'DESCENDING', 'BOTH']\n",
    "    if (ORBIT not in orbit_required):\n",
    "        raise ValueError(\"ERROR!!! Parameter ORBIT not correctly defined\")\n",
    "\n",
    "    model_required = ['DIRECT', 'VOLUME']\n",
    "    if (TERRAIN_FLATTENING_MODEL not in model_required):\n",
    "        raise ValueError(\"ERROR!!! Parameter TERRAIN_FLATTENING_MODEL not correctly defined\")\n",
    "\n",
    "    format_required = ['LINEAR', 'DB']\n",
    "    if (FORMAT not in format_required):\n",
    "        raise ValueError(\"ERROR!!! FORMAT not correctly defined\")\n",
    "\n",
    "    frame_needed = ['MONO', 'MULTI']\n",
    "    if (SPECKLE_FILTER_FRAMEWORK not in frame_needed):\n",
    "        raise ValueError(\"ERROR!!! SPECKLE_FILTER_FRAMEWORK not correctly defined\")\n",
    "\n",
    "    format_sfilter = ['BOXCAR', 'LEE', 'GAMMA MAP'\n",
    "              ,'REFINED LEE', 'LEE SIGMA']\n",
    "    if (SPECKLE_FILTER not in format_sfilter):\n",
    "        raise ValueError(\"ERROR!!! SPECKLE_FILTER not correctly defined\")\n",
    "\n",
    "    if (TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER < 0):\n",
    "        raise ValueError(\"ERROR!!! TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER not correctly defined\")\n",
    "\n",
    "    if (SPECKLE_FILTER_KERNEL_SIZE <= 0):\n",
    "        raise ValueError(\"ERROR!!! SPECKLE_FILTER_KERNEL_SIZE not correctly defined\")\n",
    "\n",
    "\n",
    "    # 1. DATA SELECTION\n",
    "    # select S-1 image collection\n",
    "    s1 = ee.ImageCollection('COPERNICUS/S1_GRD_FLOAT')\\\n",
    "        .filter(ee.Filter.eq('instrumentMode', 'IW'))\\\n",
    "        .filter(ee.Filter.eq('resolution_meters', 10)) \\\n",
    "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
    "        .filterDate(START_DATE, STOP_DATE) \\\n",
    "        .filterBounds(ROI)\n",
    "\n",
    "    # if (PLATFORM_NUMBER=='A' or PLATFORM_NUMBER=='B' ):\n",
    "    #     s1 = s1.filter(ee.Filter.eq('platform_number', PLATFORM_NUMBER))\n",
    "   \n",
    "\n",
    "    # if (ORBIT_NUM != None):\n",
    "    #     s1 = s1.filter(ee.Filter.eq('relativeOrbitNumber_start',ORBIT_NUM))\n",
    "    #     #.filter(ee.Filter.eq('relativeOrbitNumber_start',None))\n",
    "\n",
    "\n",
    "    # select orbit\n",
    "    if (ORBIT != 'BOTH'):\n",
    "        s1 = s1.filter(ee.Filter.eq('orbitProperties_pass', ORBIT))\n",
    "\n",
    "    # select polarization\n",
    "    if (POLARIZATION == 'VV'):\n",
    "        s1 = s1.select(['VV', 'angle'])\n",
    "    elif (POLARIZATION == 'VH'):\n",
    "        s1 = s1.select(['VH', 'angle'])\n",
    "    elif (POLARIZATION == 'VVVH'):\n",
    "        s1 = s1.select(['VV', 'VH', 'angle'])\n",
    "        \n",
    "    print('Number of images in collection: ', s1.size().getInfo())\n",
    "\n",
    "    # 2. ADDITIONAL BORDER NOISE CORRECTION\n",
    "    if (APPLY_BORDER_NOISE_CORRECTION):\n",
    "        s1_1 = s1.map(f_mask_edges)\n",
    "        print('Additional border noise correction is completed')\n",
    "    else:\n",
    "        s1_1 = s1\n",
    "\n",
    "    # 3. SPECKLE FILTERING\n",
    "    if (APPLY_SPECKLE_FILTERING):\n",
    "        if (SPECKLE_FILTER_FRAMEWORK == 'MONO'):\n",
    "            s1_1 = ee.ImageCollection(MonoTemporal_Filter(s1_1, SPECKLE_FILTER_KERNEL_SIZE, SPECKLE_FILTER))\n",
    "            print('Mono-temporal speckle filtering is completed')\n",
    "        else:\n",
    "            s1_1 = ee.ImageCollection(MultiTemporal_Filter(s1_1, SPECKLE_FILTER_KERNEL_SIZE, SPECKLE_FILTER, SPECKLE_FILTER_NR_OF_IMAGES))\n",
    "            print('Multi-temporal speckle filtering is completed')\n",
    "\n",
    "    # 4. TERRAIN CORRECTION\n",
    "    if (APPLY_TERRAIN_FLATTENING):\n",
    "        s1_1 = (slope_correction(s1_1, TERRAIN_FLATTENING_MODEL ,DEM, TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER))\n",
    "        print('Radiometric terrain normalization is completed')\n",
    "\n",
    "    # 5. OUTPUT\n",
    "    if (FORMAT == 'DB'):\n",
    "        s1_1 = s1_1.map(lin_to_db)\n",
    "              \n",
    "    #clip to roi\n",
    "    if (CLIP_TO_ROI):\n",
    "        s1_1 = s1_1.map(lambda image: image.clip(ROI))\n",
    "        \n",
    "    # if (SAVE_ASSET):     \n",
    "    #     size = s1_1.size().getInfo()\n",
    "    #     imlist = s1_1.toList(size)\n",
    "    #     for idx in range(0, size):\n",
    "    #         img = imlist.get(idx)\n",
    "    #         img = ee.Image(img)\n",
    "    #         name = str(img.id().getInfo())\n",
    "    #         #name = str(idx)\n",
    "    #         description = name           \n",
    "    #         assetId = ASSET_ID+'/'+name\n",
    "    #         task = ee.batch.Export.image.toAsset(image=img,\n",
    "    #                                              assetId=assetId,\n",
    "    #                                              description=description,\n",
    "    #                                              region=s1_1.geometry(),\n",
    "    #                                              scale=10,\n",
    "    #                                              maxPixels=1e13)\n",
    "    #         task.start()\n",
    "    #         print('Exporting {} to {}'.format(name, assetId))\n",
    "    \n",
    "    # print( type(s1_1) )\n",
    "    return s1_1.median()\n",
    "\n",
    "def getSAR(lon, lat, start, end):\n",
    "    parameter = {'START_DATE': start,\n",
    "                'STOP_DATE': end,        \n",
    "                'POLARIZATION': 'VVVH',\n",
    "                'ORBIT' : 'BOTH',\n",
    "                # 'ORBIT_NUM': None,\n",
    "                'ROI': ee.Geometry.Point(lon, lat).buffer(15).bounds(),\n",
    "                'APPLY_BORDER_NOISE_CORRECTION': False,\n",
    "                'APPLY_SPECKLE_FILTERING': True,\n",
    "                'SPECKLE_FILTER_FRAMEWORK': 'MULTI',\n",
    "                'SPECKLE_FILTER': 'REFINED LEE',\n",
    "                'SPECKLE_FILTER_KERNEL_SIZE': 9,\n",
    "                'SPECKLE_FILTER_NR_OF_IMAGES':10,\n",
    "                'APPLY_TERRAIN_FLATTENING': False,\n",
    "                'DEM': ee.Image('USGS/SRTMGL1_003'),\n",
    "                'TERRAIN_FLATTENING_MODEL': 'VOLUME',\n",
    "                'TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER':0,\n",
    "                'FORMAT': 'LINEAR',\n",
    "                'CLIP_TO_ROI': False,\n",
    "                'SAVE_ASSET': False,\n",
    "                # 'ASSET_ID': \n",
    "                }\n",
    "    #processed s1 collection\n",
    "    s1_processed = s1_preproc(parameter)\n",
    "    s1_processed = ee.ImageCollection.fromImages([s1_processed]).getRegion(parameter['ROI'], 10).getInfo()\n",
    "\n",
    "    return s1_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1819cada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['id', 'longitude', 'latitude', 'time', 'b1'],\n",
       "  ['aspect_90M_n00e035',\n",
       "   37.906165128227244,\n",
       "   0.023850270793373297,\n",
       "   None,\n",
       "   80.67308044433594]],\n",
       " [['id', 'longitude', 'latitude', 'time', 'b1'],\n",
       "  ['roughness_90M_n00e035',\n",
       "   37.906165128227244,\n",
       "   0.023850270793373297,\n",
       "   None,\n",
       "   4.4639692306518555]],\n",
       " [['id', 'longitude', 'latitude', 'time', 'b1'],\n",
       "  ['cti_90M_n00e035',\n",
       "   37.906165128227244,\n",
       "   0.023850270793373297,\n",
       "   None,\n",
       "   0.9176572561264038]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getElev(lon, lat):\n",
    "  point = ee.Geometry.Point(lon, lat).buffer(15).bounds()\n",
    "  elev = ee.Image(\"USGS/SRTMGL1_003\").select(['elevation'])\n",
    "  elevation = ee.ImageCollection.fromImages([elev]).getRegion(point, 30).getInfo()\n",
    "  slop = ee.Terrain.slope(elev)\n",
    "  slope = ee.ImageCollection.fromImages([slop]).getRegion(point, 30).getInfo()\n",
    "  return elevation, slope\n",
    "\n",
    "# files17 = sorted(glob.glob(os.getcwd()+'/Precipitation2017/*.tif'))\n",
    "# files18 = sorted(glob.glob(os.getcwd()+'/Precipitation2018/*.tif'))\n",
    "# files19 = sorted(glob.glob(os.getcwd()+'/Precipitation2019/*.tif'))\n",
    "# files20 = sorted(glob.glob(os.getcwd()+'/Precipitation2020/*.tif'))\n",
    "# files21 = sorted(glob.glob(os.getcwd()+'/Precipitation2021/*.tif'))\n",
    "\n",
    "def getTopo(lon, lat):\n",
    "  point = ee.Geometry.Point(lon, lat).buffer(45).bounds()\n",
    "  aspect = ee.ImageCollection(\"projects/sat-io/open-datasets/Geomorpho90m/aspect\").getRegion(point, 90).getInfo()\n",
    "  roughness = ee.ImageCollection(\"projects/sat-io/open-datasets/Geomorpho90m/roughness\").getRegion(point, 90).getInfo()\n",
    "  twi = ee.ImageCollection(\"projects/sat-io/open-datasets/Geomorpho90m/cti\").getRegion(point, 90).getInfo()\n",
    "  return aspect, roughness, twi\n",
    "\n",
    "def getPrecip(lon, lat, start, end):\n",
    "  point = ee.Geometry.Point(lon, lat).buffer(15).bounds()\n",
    "  rain = ee.ImageCollection(\"UCSB-CHG/CHIRPS/PENTAD\").select(['precipitation']).filterDate(start, end).filterBounds(point).median()\n",
    "  precipitation = ee.ImageCollection.fromImages([rain]).getRegion(point, 30).getInfo()\n",
    "  return precipitation\n",
    "\n",
    "# getElev(37.9062, 0.0236)\n",
    "# getTopo(37.9062, 0.0236)\n",
    "# getPrecip(37.9062, 0.0236, ee.Date('2021-01-01'), ee.Date('2021-12-31'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dd5b430e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Number of images in collection:  58\n",
      "Multi-temporal speckle filtering is completed\n",
      "Number of images in collection:  59\n",
      "Multi-temporal speckle filtering is completed\n",
      "1\n",
      "Number of images in collection:  58\n",
      "Multi-temporal speckle filtering is completed\n",
      "Number of images in collection:  59\n",
      "Multi-temporal speckle filtering is completed\n",
      "2\n",
      "Number of images in collection:  58\n",
      "Multi-temporal speckle filtering is completed\n",
      "Number of images in collection:  59\n",
      "Multi-temporal speckle filtering is completed\n",
      "3\n",
      "Number of images in collection:  58\n",
      "Multi-temporal speckle filtering is completed\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(columns=['longitude', 'latitude', 'year', 'SOC', 'LC', 'elev', 'slope', 'aspect', 'roughness', 'twi', \n",
    "                                  'SR_B2-1', 'SR_B3-1', 'SR_B4-1', 'SR_B5-1', 'SR_B6-1', 'SR_B7-1', 'EVI-1', 'ST_B10-1', 'VV-1', 'VH-1', 'VV/VH-1', 'prec-1',\n",
    "                                  'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'EVI', 'ST_B10', 'VV', 'VH', 'VV/VH', 'prec',\n",
    "                                  ])\n",
    "\n",
    "for i in range(len(df)):\n",
    "  print(i)\n",
    "\n",
    "  elev, slope = getElev(df.iloc[i, 0], df.iloc[i, 1])[0], getElev(df.iloc[i, 0], df.iloc[i, 1])[1]\n",
    "  aspect, roughness, twi = getTopo(df.iloc[i, 0], df.iloc[i, 1])[0], getTopo(df.iloc[i, 0], df.iloc[i, 1])[1], getTopo(df.iloc[i, 0], df.iloc[i, 1])[2]\n",
    "  newCol = pd.Series( df.iloc[i, :5].to_list() + [ elev[1][4], slope[1][4], aspect[1][4], roughness[1][4], twi[1][4] ], index=dataframe.columns[:10] )\n",
    "  \n",
    "  for j in range(2):\n",
    "    landsat = get_landsat(df.iloc[i, 0], df.iloc[i, 1], \n",
    "                       ee.Date(str(df.iloc[i, 2]-1) + '-01-01').advance(0, 'year').advance(1*j, 'year'), \n",
    "                       ee.Date(str(df.iloc[i, 2]-1) + '-12-31').advance(0, 'year').advance(1*j, 'year')\n",
    "                       )\n",
    "    sar = getSAR(df.iloc[i, 0], df.iloc[i, 1], \n",
    "                       ee.Date(str(df.iloc[i, 2]-1) + '-01-01').advance(0, 'year').advance(1*j, 'year'), \n",
    "                       ee.Date(str(df.iloc[i, 2]-1) + '-12-31').advance(0, 'year').advance(1*j, 'year')\n",
    "                       )\n",
    "    \n",
    "    precipitation = getPrecip(df.iloc[i, 0], df.iloc[i, 1], \n",
    "                       ee.Date(str(df.iloc[i, 2]-1) + '-01-01').advance(0, 'year').advance(1*j, 'year'), \n",
    "                       ee.Date(str(df.iloc[i, 2]-1) + '-12-31').advance(0, 'year').advance(1*j, 'year')\n",
    "                       )\n",
    "\n",
    "    # rain = []\n",
    "    # for file in files21[0+j*6:6+j*6]:\n",
    "    #   raster = rasterio.open(file)\n",
    "    #   array = raster.read()[0]\n",
    "\n",
    "    #   idx = raster.index(df.iloc[i, 0], df.iloc[i, 1])\n",
    "    #   rain.append(array[idx])\n",
    "    \n",
    "    addCol = pd.Series( [ landsat[1][l] for l in range(4, 12) ] \n",
    "                       + [ sar[1][l] for l in range(4, 6) ] + [ sar[1][4]/sar[1][5] ]\n",
    "                       + [ precipitation[1][4] ],\n",
    "                       index=dataframe.columns[10+j*12:22+j*12] \n",
    "                       )\n",
    "    # newCol = newCol.append(addCol)\n",
    "    newCol = pd.concat([newCol, addCol])\n",
    "    # print('newCol', newCol)\n",
    "\n",
    "    \n",
    "    if newCol.isna().any() == True:\n",
    "      print(newCol)\n",
    "    \n",
    "  # dataframe = dataframe.append(newRow, ignore_index=True)\n",
    "  dataframe.loc[i] = newCol\n",
    "  # print(dataframe)\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bd3d7046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>-4.997642</td>\n",
       "      <td>39.840597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>-4.994139</td>\n",
       "      <td>39.840058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>-4.993869</td>\n",
       "      <td>39.842753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>-4.991174</td>\n",
       "      <td>39.842214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>-4.995217</td>\n",
       "      <td>39.842484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>-4.992522</td>\n",
       "      <td>39.814726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>-4.991174</td>\n",
       "      <td>39.814187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>-4.987402</td>\n",
       "      <td>39.813917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>-4.98848</td>\n",
       "      <td>39.809605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>-4.989288</td>\n",
       "      <td>39.811761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude  longitude\n",
       "1531 -4.997642  39.840597\n",
       "1532 -4.994139  39.840058\n",
       "1533 -4.993869  39.842753\n",
       "1534 -4.991174  39.842214\n",
       "1535 -4.995217  39.842484\n",
       "...        ...        ...\n",
       "1627 -4.992522  39.814726\n",
       "1628 -4.991174  39.814187\n",
       "1629 -4.987402  39.813917\n",
       "1630  -4.98848  39.809605\n",
       "1631 -4.989288  39.811761\n",
       "\n",
       "[77 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = dataframe[dataframe.isna().any(axis=1)].loc[:, ['latitude','longitude']]\n",
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b789a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrue = pd.DataFrame(columns=dataframe.columns)\n",
    "for i in range(len(dataframe)):\n",
    "    lat = dataframe.loc[i, 'latitude']\n",
    "    lon = dataframe.loc[i, 'longitude']\n",
    "    if not ((reference['latitude'] == lat) & (reference['longitude'] == lon)).any():\n",
    "        # dftrue = dftrue.append(dataframe.loc[i])\n",
    "        dftrue.loc[i] = dataframe.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e0caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>year</th>\n",
       "      <th>SOC</th>\n",
       "      <th>LC</th>\n",
       "      <th>elev</th>\n",
       "      <th>slope</th>\n",
       "      <th>SR_B2-1</th>\n",
       "      <th>SR_B3-1</th>\n",
       "      <th>SR_B4-1</th>\n",
       "      <th>...</th>\n",
       "      <th>SR_B4</th>\n",
       "      <th>SR_B5</th>\n",
       "      <th>SR_B6</th>\n",
       "      <th>SR_B7</th>\n",
       "      <th>EVI</th>\n",
       "      <th>ST_B10</th>\n",
       "      <th>VV</th>\n",
       "      <th>VH</th>\n",
       "      <th>VV/VH</th>\n",
       "      <th>prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [longitude, latitude, year, SOC, LC, elev, slope, SR_B2-1, SR_B3-1, SR_B4-1, SR_B5-1, SR_B6-1, SR_B7-1, EVI-1, ST_B10-1, VV-1, VH-1, VV/VH-1, prec-1, SR_B2, SR_B3, SR_B4, SR_B5, SR_B6, SR_B7, EVI, ST_B10, VV, VH, VV/VH, prec]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrue[dftrue.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "84f1814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrue.to_csv(os.getcwd() + '/SOCtrue.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference.to_csv(os.getcwd() + '/SOCfalse.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
